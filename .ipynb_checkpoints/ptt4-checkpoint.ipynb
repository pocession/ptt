{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize\n",
      "run main\n",
      "run subforum\n",
      "Enter which sub forum you want to scrape data from: Japan_Travel\n",
      "How many pages do you want: 20\n",
      "run index_page\n",
      "run pagelist\n",
      "Total page number is 6519.\n",
      "Get all url of pages ... done\n"
     ]
    }
   ],
   "source": [
    "# Some practice for scraping ptt\n",
    "# This python scapper allows you to get article title, review count and url of this article from ptt\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Enter the subforum which you want to scrape data from\n",
    "# Subforum name is case sensitive\n",
    "def subforum():\n",
    "    print(\"run subforum\")\n",
    "    name = input(\"Enter which sub forum you want to scrape data from: \")\n",
    "    page = int(input(\"How many pages do you want: \"))\n",
    "    return(name, page)\n",
    "\n",
    "\n",
    "# Return contend of the first page, index_page, which is a bs4.BeautifulSoup object\n",
    "def index_page(a,b):\n",
    "    print(\"run index_page\")\n",
    "    name = a\n",
    "    page = b\n",
    "    url = \"https://www.ptt.cc/bbs/\"+name+\"/index.html\"\n",
    "    response = requests.get(url, cookies={'over18': '1'}) \n",
    "    result = response.text\n",
    "    index = BeautifulSoup(result, 'html.parser')\n",
    "    return (index)\n",
    "\n",
    "\n",
    "# Create a list to store url of all scrapped pages\n",
    "# This list is a index for scrapping contends\n",
    "def pagelist(index,a,b):\n",
    "    print(\"run pagelist\")\n",
    "    name = a\n",
    "    page = b\n",
    "    page_list = []\n",
    "    # Store the first page\n",
    "    a = index.find_all('a', attrs={'class':'btn wide'})\n",
    "    page_number = a[1]['href']\n",
    "    page_scrapped = \"https://www.ptt.cc/bbs/\"+name+\"/index.html\"\n",
    "    page_list.append(page_scrapped)\n",
    "    \n",
    "    # Get page number\n",
    "    # Extract page number by replace non-integer characters with NONE\n",
    "    # Plus 1 page to page number for index\n",
    "    fix = \"/bbs/{url}/index\".format(url = name)\n",
    "    page_number = int(page_number.replace(\"{a}\".format(a = fix),\"\").replace(\".html\",\"\")) + 1\n",
    "    print(\"Total page number is {a}.\".format(a = page_number))\n",
    "    \n",
    "    # Get url of pages\n",
    "    k = 0\n",
    "    while k < page:\n",
    "        page_scrapped_x = page_number - (k)\n",
    "        page_scrapped_y = str(page_scrapped_x)\n",
    "        page_scrapped_y = \"https://www.ptt.cc/bbs/\"+name+\"/index\"+page_scrapped_y+\".html\"\n",
    "        page_list.append(page_scrapped_y)\n",
    "        k += 1\n",
    "    print(\"Get all url of pages ... done\")\n",
    "    return(page_list)\n",
    "    \n",
    "\n",
    "# Get each article information, including title, review counts and url  \n",
    "\n",
    "# Write it into a SQL\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"run main\")\n",
    "    name,page = subforum()\n",
    "    soup=index_page(name,page)\n",
    "    page_list=pagelist(soup,name,page)\n",
    "    print(soup)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"initialize\")\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-468935a8f34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
